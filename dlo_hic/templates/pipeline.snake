import logging
import os
from os.path import join
import sys

import dlo_hic.config
import dlo_hic.tools.helper as dlo_help
import dlo_hic.tools.main_process as dlo_main
import dlo_hic.tools.quality_control as dlo_qc
from dlo_hic.utils.pipeline import *

pipeline_log = logging.getLogger("pipeline")
root_log = logging.getLogger()
root_log.setLevel(10)
console = logging.StreamHandler(stream=sys.stderr)
formatter = logging.Formatter(
    fmt=dlo_hic.config.LOGGING_FMT,
    datefmt=dlo_hic.config.LOGGING_DATE_FMT)
console.setFormatter(formatter)

# parse config
config_file = "./pipeline_config.ini"
config = parse_config(config_file)
if config['GLOBAL']['log_level'] <= 10:
    pipeline_log.debug(config)

root_log.setLevel(config['GLOBAL']['log_level'])

# load global settings
setting = load_global_setting(config)
output_files = output_files(setting)
sub_dir = sub_dir(setting)
qc_files = pipeline_qc_files(setting)
local_logger = local_logger(setting)

pipeline_log.info("working at %s"%setting.working_dir)
make_result_dirs(setting.working_dir)

####################################
# Rule Definition
####################################

ALL = get_targets(setting)

rule all:
    input:
        ALL


rule extract_PET:
    # --------------------
    # 1. extract_PET
    #
    #  Tool Interface:
    #     ( fastq, out1, out2,
    #       linker_a, linker_b,
    #       mismatch, rest, processes, PET_len_range, PET_cut_len,
    #       adapter, mismatch_adapter,
    #       log_file, flag_file, chunk_size )
    # --------------------
    threads: setting.ncpu
    input:
        get_input_fastq(setting.input_dir)
    output:
        pet1 = output_files('{sample}')['pet1.fq'],
        pet2 = output_files('{sample}')['pet2.fq'],
        trim_flag = output_files('{sample}')['trim_flag'],
        qc_comp = qc_files('{sample}')['extract_PET']['comp']
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("extract_PET")

        conf = config['EXTRACT_PET']
        rest = config['DATA']['restriction_site']

        chunk_size = 100000
        # run tool
        dlo_main.extract_PET.log = llog
        dlo_main.extract_PET.main(
            input[0], output.pet1, output.pet2,
            conf['linker_a'], conf['linker_b'],
            conf['mismatch'], rest, setting.ncpu, conf['pet_len_range'], conf['pet_cut_len'],
            conf['adapter'], conf['mismatch_adapter'],
            output.qc_comp, output.trim_flag, chunk_size)


rule build_bedpe:
    # --------------------
    # 2. build_bedpe
    #
    #  Tool Interface:
    #     ( file_format, input1, input2, bedpe,
    #       ncpu, bwa_index, mapq, upper_tri,
    #       log_file, bwa_log_file )
    # --------------------
    threads: setting.ncpu
    input:
        rules.extract_PET.output
    output:
        bedpe      = output_files("{sample}")["uniq.bedpe"],
        pet1_bam   = output_files("{sample}")["pet1.bam"],
        pet2_bam   = output_files("{sample}")["pet2.bam"],
        pet1_uniq_bam = output_files("{sample}")["pet1.uniq.bam"],
        pet2_uniq_bam = output_files("{sample}")["pet2.uniq.bam"],
        pet1_mul_bam = output_files("{sample}")["pet1.mul.bam"],
        pet2_mul_bam = output_files("{sample}")["pet2.mul.bam"],
        pet1_unm_bam = output_files("{sample}")["pet1.unm.bam"],
        pet2_unm_bam = output_files("{sample}")["pet2.unm.bam"],
        pet1_bed   = output_files("{sample}")["pet1.bed"],
        pet2_bed   = output_files("{sample}")["pet2.bed"],
        qc_bedpe   = qc_files('{sample}')['build_bedpe']['build_bedpe']
    params:
        llog = local_logger,
        bwa_log    = sub_dir("log") + "/{sample}.bwa.log",
    run:
        llog = params.llog
        llog.log_stage_boundary("build_bedpe")

        # load parameters
        conf = config['BUILD_BEDPE']

        bwa_index = config['DATA']['bwa_index_prefix']

        # run tool
        dlo_main.build_bedpe.log = llog
        dlo_main.build_bedpe.main(
            'fastq', input[0], input[1], output.bedpe,
            setting.ncpu, bwa_index, conf['mapq'], True,
            output.qc_bedpe, params.bwa_log)


rule qc_count_bedpe:
    # --------------------
    # qc_count_bedpe
    #
    # Generate bedpe counting report for quality control.
    # 
    #  Tool Interface:
    #     ( input, log_file, long_range_cutoff )
    # --------------------
    threads: 1
    input:
        rules.build_bedpe.output
    output:
        qc_files('{sample}')['build_bedpe']['comp']
    run:
        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output[0], cutoff)


rest_name = config['DATA']['restriction_name']
rest_bed_gz = config['NOISE_REDUCE']['restriction_sites_bed']
if not rest_bed_gz:
    rest_bed_gz = join(setting.working_dir, rest_name + ".bed")
rest_bed_gz_idx = rest_bed_gz + ".tbi"

fasta = config['DATA']['fasta']


rule extract_rest_sites:
    # --------------------
    # extract_rest_sites
    # 
    #  Tool Interface:
    #     ( fasta, rest, output, processes )
    # --------------------
    threads: setting.ncpu
    input: fasta
    output: rest_bed_gz, rest_bed_gz_idx
    run:
        rest = config['DATA']['restriction_site']
        rest = rest.replace("*", "")
        dlo_help.extract_rest_sites.main(
            fasta, rest, output[0], setting.ncpu)


rule noise_reduce:
    # --------------------
    # 3. noise_reduce
    #
    #  Tool Interface:
    #     ( bedpe, output,
    #       restriction, processes,
    #       threshold_span )
    # --------------------
    threads: setting.ncpu
    input:
        bedpe = rules.build_bedpe.output.bedpe,
        rest_bed_gz = rest_bed_gz
    output: 
        output_files("{sample}")['nr.bedpe'],
        output_files("{sample}")['nr.bedpe.sel'],
        output_files("{sample}")['nr.bedpe.re'],
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("noise_reduce")

        # load parameters
        conf = config['NOISE_REDUCE']

        bedpe = input.bedpe
        out = output[0]
        restriction = input.rest_bed_gz
        thresh_span = conf['threshold_span']

        # run tool
        dlo_main.noise_reduce.log = llog
        dlo_main.noise_reduce.main(
            bedpe, out,
            restriction, setting.ncpu, thresh_span)


rule qc_count_bedpe_nr:
    # --------------------
    # count_bedpe
    #
    # Generate nr bedpe counting report for quality control.
    # 
    #  Tool Interface:
    #     ( input, log_file, long_range_cutoff )
    # --------------------
    threads: 1
    input:
        rules.noise_reduce.output
    output:
        qc_files('{sample}')['noise_reduce']['comp'],
        qc_files('{sample}')['noise_reduce']['comp_abnormal_sel'],
        qc_files('{sample}')['noise_reduce']['comp_abnormal_re'],
    run:
        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output[0], cutoff)
        dlo_qc.interactions_qc.main(input[1], output[1], cutoff)
        dlo_qc.interactions_qc.main(input[2], output[2], cutoff)


rule bedpe2pairs:
    # --------------------
    # 4. bedpe2pairs:
    #
    #  Tool Interface:
    #     ( bedpe, pairs, keep, remove_redundancy, ncpu )
    # --------------------
    threads: setting.ncpu
    input:
        rules.noise_reduce.output
    output:
        [ output_files("{sample}")["pairs.gz"], output_files("{sample}")["pairs.gz.px2"] ] +\
        ([output_files("{sample}")["pairs"]] if '.hic' in setting.result_formats else [])
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("bedpe2pairs")

        if '.hic' in setting.result_formats:
            keep_ = True
        else:
            keep_ = False

        out = output[0].replace(".gz", "")

        # run tool
        dlo_main.bedpe2pairs.log = llog
        dlo_main.bedpe2pairs.main(input[0], out, keep_, True, setting.ncpu)


rule qc_pairs:
    # --------------------
    #  pairs quility control
    #
    #  Tool Interfaces:
    #
    #  1. chrs_interactions:
    #     ( input, chromosome_file, output )
    # --------------------
    threads: 1
    input:
        rules.bedpe2pairs.output
    output:
        chr_interactions = qc_files('{sample}')['bedpe2pairs']['chr_interactions'],
        comp = qc_files('{sample}')['bedpe2pairs']['comp'],
        pet_span_stats = qc_files('{sample}')['bedpe2pairs']['pet_span_stats'],
        pet_span_fig = qc_files('{sample}')['bedpe2pairs']['pet_span_fig'],
    run:
        chrom_file = setting.chromosome_file
        supported = supported_chromosomes()
        if chrom_file in supported:
            chrom_id = chrom_file
            chrom_file = supported[chrom_id]
        dlo_qc.chr_interactions.main(input[0], chrom_file, output.chr_interactions)

        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output.comp, cutoff)
        sample_lines = 1000
        hist_bins = 1000
        dlo_qc.PET_span_stats.main(input[0], output.pet_span_stats, output.pet_span_fig, sample_lines, hist_bins)


rule to_hic:
    # --------------------
    # convert .pairs to .hic file
    #
    # call command:
    #   java juicertools.jar pre
    # --------------------
    threads: setting.ncpu
    input:
        rules.bedpe2pairs.output
    output:
        hic = output_files("{sample}")['hic'],
    params:
        log = join(sub_dir("log"),  "{sample}.juicertools.log")
    run:
        conf = config['RESULT']

        input_pairs = input[2]
        resolutions = config['RESULT']['resolutions']
        resolutions = ",".join([str(r) for r in resolutions])

        with open(params.log, 'w') as f_log:
            p = subprocess.check_call(
                ['java', '-jar', conf['juicer_tools_jar'], 'pre', input_pairs, output.hic, setting.chromosome_file, '-r', resolutions],
                stderr=f_log, stdout=f_log)


rule to_cooler:
    # --------------------
    # convert .pairs to .cool file
    # 
    # call command:
    #   cooler makebins
    #   cooler cload
    #   cooler balance (optional)
    #   cooler zoomify (optional)
    # --------------------
    threads: setting.ncpu
    input:
        rules.bedpe2pairs.output
    output:
        [ output_files("{sample}")['cool'] ] +\ 
        ([ output_files("{sample}")['mcool'] ] if config['RESULT']['zoomify'] else [])
    params:
        log  = join(sub_dir('log'), '{sample}.cooler.log')
    run:
        chrom_file = setting.chromosome_file

        conf = config['RESULT']
        binsize = str(conf['binsize'])
        balance = conf['balance']
        zoomify = conf['zoomify']

        input_pairs = input[0]
        outcool = output[0]
        bed = outcool + ".tmp.bed"

        supported = supported_chromosomes()
        if chrom_file in supported:
            chrom_id = chrom_file
            chrom_file = supported[chrom_id]

        with open(bed, 'w') as f, open(params.log, 'w') as f_log:
            subprocess.check_call(['cooler', 'makebins', chrom_file, binsize], stdout=f, stderr=f_log)
            subprocess.check_call(['cooler', 'cload', 'pairix', bed, input_pairs, outcool], stderr=f_log)
            if balance:
                subprocess.check_call(['cooler', 'balance', '-p', str(setting.ncpu), outcool], stderr=f_log)
            if zoomify:
                subprocess.check_call(['cooler', 'zoomify', '-p', str(setting.ncpu), outcool], stderr=f_log)


rule qc_gen_report:
    # --------------------
    # generate QC report
    #
    #  Tool Interface:
    #     ( pipe_workdir, output_dir, out_format )
    # --------------------
    threads: 1
    input:
        all_qc_files('{sample}', workdir=setting.working_dir)
    output:
        join(sub_dir("qc"), "{sample}." + setting.qc_report_format)
    run:
        dlo_qc.gen_qc_report.main(setting.working_dir, output[0], setting.qc_report_format)

import logging
import os
import sys

import dlo_hic.config
import dlo_hic.tools.helper as dlo_help
import dlo_hic.tools.main_process as dlo_main
import dlo_hic.tools.quality_control as dlo_qc
from dlo_hic.utils.pipeline import *

pipeline_log = logging.getLogger("pipeline")
root_log = logging.getLogger()
root_log.setLevel(10)
console = logging.StreamHandler(stream=sys.stderr)
formatter = logging.Formatter(
    fmt=dlo_hic.config.LOGGING_FMT,
    datefmt=dlo_hic.config.LOGGING_DATE_FMT)
console.setFormatter(formatter)

# parse config
config_file = "./pipeline_config.ini"
config = parse_config(config_file)
if config['GLOBAL']['loglevel'] <= 10:
    pipeline_log.debug(config)

root_log.setLevel(config['GLOBAL']['loglevel'])

# load global settings
setting = load_global_setting(config)
output_files = output_files(setting)

pipeline_log.info("working at %s"%setting.working_dir)
os.chdir(setting.working_dir)
make_result_dirs()

####################################
# Rule Definition
####################################

ALL = get_targets(setting)

rule all:
    input:
        ALL


rule extract_PET:
    # --------------------
    # 1. extract_PET
    #
    #  Tool Interface:
    #     ( fastq, out1, out2,
    #       linker_a, linker_b,
    #       mismatch, rest, phred, processes, PET_len,
    #       log_file )
    # --------------------
    threads: setting.ncpu
    input:
        get_input_fastq(setting.input_dir)
    output:
        pet1 = output_files('{sample}')['pet1.fq'],
        pet2 = output_files('{sample}')['pet2.fq'],
        qc_log = qc_logs('{sample}')['extract_PET']
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("extract_PET")

        conf = config['EXTRACT_PET']
        rest = config['DATA']['restriction_site']

        # run tool
        dlo_main.extract_PET.log = llog
        dlo_main.extract_PET.main(
            input[0], output.pet1, output.pet2, conf['linker-a'], conf['linker-b'],
            conf['mismatch'], rest, conf['phred'],
            setting.ncpu, conf['pet_len'], output.qc_log)


rule build_bedpe:
    # --------------------
    # 2. build_bedpe
    #
    #  Tool Interface:
    #     ( file_format, input1, input2, bedpe,
    #       ncpu, bwa_index, mapq,
    #       bwa_log_file )
    # --------------------
    threads: setting.ncpu
    input:
        rules.extract_PET.output
    output:
        bedpe      = output_files("{sample}")["uniq.bedpe"],
        pet1_bam   = output_files("{sample}")["pet1.bam"],
        pet2_bam   = output_files("{sample}")["pet2.bam"],
        pet1_f_bam = output_files("{sample}")["pet1.filtered.bam"],
        pet2_f_bam = output_files("{sample}")["pet2.filtered.bam"],
        pet1_bed   = output_files("{sample}")["pet1.bed"],
        pet2_bed   = output_files("{sample}")["pet2.bed"],
        bwa_log    = sub_dir("log") + "/{sample}.bwa.log"
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("build_bedpe")

        # load parameters
        conf = config['BUILD_BEDPE']

        bwa_index = config['DATA']['bwaindexprefix']

        # run tool
        dlo_main.build_bedpe.log = llog
        dlo_main.build_bedpe.main(
            'fastq', input[0], input[1], output.bedpe,
            setting.ncpu, bwa_index, conf['mapq'], output.bwa_log)


rule qc_count_bedpe:
    # --------------------
    # qc_count_bedpe
    #
    # Generate bedpe counting report for quality control.
    # 
    #  Tool Interface:
    #     ( input, log_file, long_range_cutoff )
    # --------------------
    threads: 1
    input:
        rules.build_bedpe.output
    output:
        qc_logs('{sample}')['build_bedpe']
    run:
        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output[0], cutoff)


rest_name = config['DATA']['restriction_name']
rest_bed_gz = config['NOISE_REDUCE']['restriction_sites_bed']
if not rest_bed_gz:
    rest_bed_gz = rest_name + ".bed.gz"
rest_bed_gz_idx = rest_bed_gz + ".tbi"

fasta = config['DATA']['fasta']


rule extract_rest_sites:
    # --------------------
    # extract_rest_sites
    # 
    #  Tool Interface:
    #     ( fasta, rest, output, processes )
    # --------------------
    threads: setting.ncpu
    input: fasta
    output: rest_bed_gz, rest_bed_gz_idx
    run:
        rest = config['DATA']['restriction_site']
        rest = rest.replace("*", "")
        dlo_help.extract_rest_sites.main(
            fasta, rest, output[0], setting.ncpu)


rule noise_reduce:
    # --------------------
    # 3. noise_reduce
    #
    #  Tool Interface:
    #     ( bedpe, output,
    #       restriction, processes,
    #       threshold_num_rest, threshold_span )
    # --------------------
    threads: setting.ncpu
    input:
        rules.build_bedpe.output + \
        [ rest_bed_gz, rest_bed_gz_idx ]
    output: 
        output_files("{sample}")['nr.bedpe'],
        output_files("{sample}")['nr.bedpe.err']
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("noise_reduce")

        # load parameters
        conf = config['NOISE_REDUCE']

        bedpe = input[0]
        out = output[0]
        restriction = input[1]
        thresh_num = conf['threshold_num_rest']
        thresh_span = conf['threshold_span']

        # run tool
        dlo_main.noise_reduce.log = llog
        dlo_main.noise_reduce.main(
            bedpe, out,
            restriction, setting.ncpu, thresh_num, thresh_span)


rule qc_count_bedpe_nr:
    # --------------------
    # count_bedpe
    #
    # Generate nr bedpe counting report for quality control.
    # 
    #  Tool Interface:
    #     ( input, log_file, long_range_cutoff )
    # --------------------
    threads: 1
    input:
        rules.noise_reduce.output
    output:
        qc_logs('{sample}')['noise_reduce'],
        qc_logs('{sample}')['noise_reduce.err']
    run:
        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output[0], cutoff)
        dlo_qc.interactions_qc.main(input[1], output[1], cutoff)


rule remove_redundancy:
    # --------------------
    # 4. remove_redundancy:
    #
    #  Tool Interface:
    #     ( bedpe, output, distance )
    # --------------------
    threads: setting.ncpu
    input:
        rules.noise_reduce.output
    output:
        output_files("{sample}")["rr.bedpe"]
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("remove_redundancy")

        # load parameters
        distance = config['REMOVE_REDUNDANCY']['distance']

        # run tool
        dlo_main.remove_redundancy.log = llog
        dlo_main.remove_redundancy.main(
            input[0], output[0], distance)


rule qc_count_bedpe_rr:
    # --------------------
    # count_bedpe
    #
    # Generate rr bedpe counting report for quality control.
    # 
    #  Tool Interface:
    #     ( input, log_file, long_range_cutoff )
    # --------------------
    threads: 1
    input:
        rules.remove_redundancy.output
    output:
        qc_logs('{sample}')['remove_redundancy']
    run:
        cutoff = config['QUALITY_CONTROL']['long_range_cutoff']
        dlo_qc.interactions_qc.main(input[0], output[0], cutoff)


rule bedpe2pairs:
    # --------------------
    # 6. bedpe2pairs:
    #
    #  Tool Interface:
    #     ( bedpe, pairs, keep )
    # --------------------
    threads: setting.ncpu
    input:
        rules.remove_redundancy.output
    output:
        [ output_files("{sample}")["pairs.gz"], output_files("{sample}")["pairs.gz.px2"] ] +\
        ([output_files("{sample}")["pairs"]] if '.hic' in setting.result_formats else [])
    params:
        llog = local_logger
    run:
        llog = params.llog
        llog.log_stage_boundary("bedpe2pairs")

        if '.hic' in setting.result_formats:
            keep_ = True
        else:
            keep_ = False

        out = output[0].replace(".gz", "")

        # run tool
        dlo_main.bedpe2pairs.log = llog
        dlo_main.bedpe2pairs.main(input[0], out, keep_)


rule to_hic:
    # --------------------
    # convert .pairs to .hic file
    #
    # call command:
    #   java juicertools.jar pre
    # --------------------
    threads: setting.ncpu
    input:
        rules.bedpe2pairs.output
    output:
        hic = output_files("{sample}")['hic'],
    params:
        log = sub_dir("log") + "/{sample}.juicertools.log"
    run:
        conf = config['RESULT']

        input_pairs = input[2]
        resolutions = config['RESULT']['resolutions']
        resolutions = ",".join([str(r) for r in resolutions])

        with open(params.log, 'w') as f_log:
            p = subprocess.check_call(
                ['java', '-jar', conf['juicertoolsjar'], 'pre', input_pairs, output.hic, conf['genomeid'], '-r', resolutions],
                stderr=f_log, stdout=f_log)


rule to_cooler:
    # --------------------
    # convert .pairs to .cool file
    # 
    # call command:
    #   cooler makebins
    #   cooler cload
    #   cooler balance (optional)
    #   cooler zoomify (optional)
    # --------------------
    threads: setting.ncpu
    input:
        rules.bedpe2pairs.output
    output:
        [ output_files("{sample}")['cool'] ] +\ 
        ([ output_files("{sample}")['mcool'] ] if config['RESULT']['zoomify'] else [])
    params:
        log  = sub_dir('log') + '/{sample}.cooler.log'
    run:
        conf = config['RESULT']
        chrom_file = conf['chromosomefile']

        binsize = str(conf['binsize'])
        balance = conf['balance']
        zoomify = conf['zoomify']

        input_pairs = input[0]
        outcool = output[0]
        bed = outcool + ".tmp.bed"

        is_gen_chrom_file = False
        chrom_files = chromosome_files()
        if chrom_file in chrom_files:
            chrom_id = chrom_file
            chrom_file = sub_dir(6) + '/' + os.path.split(chrom_files[chrom_id])[1]
            gen_chromosome_file(conf['chromosomefile'], chrom_file)
            is_gen_chrom_file = True

        with open(bed, 'w') as f, open(params.log, 'w') as f_log:
            subprocess.check_call(['cooler', 'makebins', chrom_file, binsize], stdout=f, stderr=f_log)
            subprocess.check_call(['cooler', 'cload', 'pairix', bed, input_pairs, outcool], stderr=f_log)
            if balance:
                subprocess.check_call(['cooler', 'balance', '-p', str(setting.ncpu), outcool], stderr=f_log)
            if zoomify:
                subprocess.check_call(['cooler', 'zoomify', '-p', str(setting.ncpu), outcool], stderr=f_log)

        subprocess.check_call(['rm', bed])
        if is_gen_chrom_file:
            subprocess.check_call(['rm', chrom_file])


rule qc_gen_report:
    # --------------------
    # generate QC report
    #
    #  Tool Interface:
    #     ( pipe_workdir, output_dir, out_format )
    # --------------------
    threads: 1
    input:
        qc_logs('{sample}').values()
    output:
        sub_dir("qc") + "/" + "{sample}." + setting.qc_report_format
    run:
        dlo_qc.gen_qc_report.main(setting.working_dir, sub_dir("qc"), setting.qc_report_format)
